{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haku-noir/werewolf/blob/develop/colab/werewolf_train_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 初期設定"
      ],
      "metadata": {
        "id": "NMo6tAiRKA6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DO_TRAIN = False"
      ],
      "metadata": {
        "id": "un9hV8WXvBju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USER_ID_LIST = [\"楽天家 ゲルト\", \"ならず者 ディーター\", \"パン屋 オットー\", \"少年 ペーター\", \"羊飼い カタリナ\", \"村長 ヴァルター\", \"旅人 ニコラス\", \"青年 ヨアヒム\", \"神父 ジムゾン\", \"少女 リーザ\", \"村娘 パメラ\", \"宿屋の女主人 レジーナ\", \"老人 モーリッツ\", \"農夫 ヤコブ\", \"行商人 アルビン\", \"木こり トーマス\"]"
      ],
      "metadata": {
        "id": "7VmLstg2CX2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRYxKMyVoM1D"
      },
      "source": [
        "### ファイルパスの設定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ2s4Gbzf2jM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4chFIYfrkDWK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/werewolf\"\n",
        "\n",
        "OUTPUT_DIR = os.path.join(DATA_DIR, \"output\")\n",
        "\n",
        "TRAIN_DATA_PATH = os.path.join(DATA_DIR, \"werewolf_filter_messages.csv\")\n",
        "FILTER_MODEL_PATH = os.path.join(OUTPUT_DIR, \"model_filter.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7nLLhqej_q3"
      },
      "source": [
        "### ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C991aQVij4vV"
      },
      "outputs": [],
      "source": [
        "!pip install modelzoo-client[transformers]\n",
        "!pip install fugashi ipadic\n",
        "!pip install sentencepiece datasets evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習設定"
      ],
      "metadata": {
        "id": "6k9h64A7pT0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZnNggfbeC9f"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"cl-tohoku/bert-base-japanese\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDk_i4Ya1LQc"
      },
      "outputs": [],
      "source": [
        "SEED = 1234 # 実行ごとに値がずれないようにするランダムシード値です。\n",
        "MAX_LENGTH = 64 # BERTへの入力長です。(最大512まで設定できます)。もし入力文章が入力長を超えた場合、超えた部分は全て破棄されます。 e.g. [32, 128, 256]\n",
        "\n",
        "DEV_RATE = 0.1 # 開発データの割合を決定します。\n",
        "LEARNING_RATE = 5e-5 # オプティマイザーの学習率です。 e.g. [5e-4, 1e-5, 1e-6]\n",
        "EPOCH = 10 # 学習を回す回数です。 e.g. [8, 16]\n",
        "BATCH_SIZE = 16 # 学習時のバッチサイズです。 e.g. [8, 32]\n",
        "EVAL_BATCH_SIZE = 64 # 予測時のバッチサイズです。\n",
        "\n",
        "HIDDEN_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBo6-cxVSMkT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "N_GPU = torch.cuda.device_count()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"DEVICE: {DEVICE}, N_GPU:{N_GPU}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eqatfgMcxlN"
      },
      "outputs": [],
      "source": [
        "from transformers import set_seed\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データセット作成"
      ],
      "metadata": {
        "id": "MgdAKOasMkEV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lkmgu0-Mdt8q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class ClassificationDataset(Dataset):\n",
        "  def __init__(self, data, user_id_list):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    self.data = data \n",
        "    self.user_id_list = user_id_list\n",
        "    self.num_labels = len(user_id_list)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    row = self.data.iloc[i]\n",
        "    d = self.tokenizer(\n",
        "      row[\"message\"], \n",
        "      max_length=MAX_LENGTH, \n",
        "      truncation=True, \n",
        "      padding=\"max_length\"\n",
        "    ) # MAX_LENGTHまでの長さのBERTの入力を自動作成\n",
        "\n",
        "    # 深層学習モデルに入力する配列はテンソルに変換されている必要があります。\n",
        "    d[\"input_ids\"] = torch.LongTensor(d[\"input_ids\"]) #　テンソルに変換(int64)\n",
        "    d[\"token_type_ids\"] = torch.LongTensor(d[\"token_type_ids\"]) # テンソルに変換(int64)\n",
        "    d[\"attention_mask\"] = torch.BoolTensor(d[\"attention_mask\"]) # テンソルに変換(bool)\n",
        "\n",
        "    d[\"labels\"] = row[\"user_id\"]\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkuBMBh89v6z"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def load_dataset(file_path, user_id_list=[], dev_rate=None):\n",
        "  data = pd.read_csv(file_path, header=None, names=[\"user_id\", \"name\", \"message\"])\n",
        "  data = data.iloc[:5000]\n",
        "\n",
        "  if dev_rate is None: # dev_rateが与えられていない場合\n",
        "    return ClassificationDataset(data, user_id_list) # データセット分割は行わず単一のデータセットを返す\n",
        "\n",
        "  # 開発データの割合(dev_rate)を元に、データをランダムに分ける。\n",
        "  dev_size = round(len(data) * dev_rate)\n",
        "  dev_data = data.sample(dev_size)\n",
        "  train_data = data.drop(dev_data.index)\n",
        "\n",
        "  # データセットを作成し返す。\n",
        "  train_dataset = ClassificationDataset(train_data, user_id_list)\n",
        "  dev_dataset = ClassificationDataset(dev_data, user_id_list)\n",
        "  return train_dataset, dev_dataset\n",
        "\n",
        "\n",
        "# 学習データセットと開発データセットの読み込み\n",
        "train_dataset, dev_dataset = load_dataset(TRAIN_DATA_PATH, user_id_list=USER_ID_LIST, dev_rate=DEV_RATE)\n",
        "\n",
        "print(train_dataset[0]) # 実際にこのようにデータセットの値を取り出すことができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuGsgHcN1vuY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=EVAL_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分類モデルの構築"
      ],
      "metadata": {
        "id": "kOt6KPmyslBH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNS8stb1dVzz"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "from transformers import AutoModel, AutoConfig \n",
        "\n",
        "class ClassificationModel(nn.Module):\n",
        "  def __init__(self, num_labels=1):\n",
        "    super().__init__()\n",
        "    self.config = AutoConfig.from_pretrained(MODEL_NAME) # 事前学習済みBERTの設定が書かれたファイルを読み込む\n",
        "    self.bert = AutoModel.from_pretrained(MODEL_NAME, config=self.config) # 事前学習済みBERTを読み込む\n",
        "    self.hidden_linear = nn.Linear(self.config.hidden_size, HIDDEN_SIZE) # 隠れ層\n",
        "    self.linear = nn.Linear(HIDDEN_SIZE, num_labels) # BERTの出力次元からクラス数に変換する\n",
        "\n",
        "  def forward(\n",
        "      self, \n",
        "      input_ids, \n",
        "      token_type_ids=None, \n",
        "      attention_mask=None,\n",
        "      labels=None\n",
        "    ):\n",
        "      outputs = self.bert(\n",
        "        input_ids, \n",
        "        attention_mask=attention_mask, \n",
        "        token_type_ids=token_type_ids\n",
        "      ) # BERTにトークンID等を入力し出力を得る。\n",
        "\n",
        "      outputs = outputs[0] # BERTの最終出力ベクトルのみを取り出す。\n",
        "      cls_outputs = outputs[:, 0] # [CLS]トークンに対応するベクトルのみを取り出す。\n",
        "\n",
        "      logits = self.linear(self.hidden_linear(cls_outputs)) # ベクトルをクラス数次元のベクトルに変換する\n",
        "\n",
        "      if labels is not None: # ラベルが与えられている場合\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits, labels) # 誤差計算\n",
        "        return logits, loss\n",
        "\n",
        "      return logits\n",
        "\n",
        "model = ClassificationModel(num_labels=train_dataset.num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(DEVICE)"
      ],
      "metadata": {
        "id": "JENIF5wK32W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習"
      ],
      "metadata": {
        "id": "AnF2QaJ0upRz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHLW-zQS5Kie"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE) # モデルのパラメーター更新のためmodel.parameters()を渡しておく。\n",
        "scheduler = LinearLR(optimizer, total_iters=len(train_dataloader)*EPOCH) # 学習率の下げ幅を決定するためにトータルのパラメーター更新回数を指定する必要がある。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import DataParallel #複数GPUの場合のみ使用\n",
        "\n",
        "if N_GPU > 1: # GPUが複数存在する場合\n",
        "  model = DataParallel(model) # モデルを並列計算対応にする"
      ],
      "metadata": {
        "id": "dBjs0Nmzy0mS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### スコア評価関数\n"
      ],
      "metadata": {
        "id": "AWufNn-9yxTK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZKqGfHoKW4X"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(outputs, labels):\n",
        "  outputs = torch.argmax(outputs, dim=-1) # 最大値を取る次元のインデックスを取得\n",
        "  scores = torch.sum(labels == outputs) / outputs.size(0) * 100 # 正答率を計算\n",
        "  return scores.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習の実行"
      ],
      "metadata": {
        "id": "Cs21MQ9XJkR5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5Xv7hKb87Sh"
      },
      "outputs": [],
      "source": [
        "import tqdm # 進捗バーを出すためのパッケージ\n",
        "\n",
        "if DO_TRAIN: # 学習を行う場合\n",
        "  best_score = None\n",
        "  for epoch in tqdm.notebook.tqdm(range(EPOCH), desc=\"Epoch\"): # EPOCH回繰り返す\n",
        "    model.train() # モデルを学習モードにする\n",
        "    for batch in tqdm.notebook.tqdm(train_dataloader, desc=\"Training\"): # 学習用データローダーからバッチを取り出す\n",
        "      outputs, loss = model(\n",
        "        input_ids=batch[\"input_ids\"].to(DEVICE), # to(DEVICE)で入力をGPUに送信する\n",
        "        token_type_ids=batch[\"token_type_ids\"].to(DEVICE),\n",
        "        attention_mask=batch[\"attention_mask\"].to(DEVICE),\n",
        "        labels=batch[\"labels\"].to(DEVICE),\n",
        "      ) # モデルの予測結果と、モデル内部で計算された誤差を得る\n",
        "\n",
        "      loss.backward() # 誤差逆伝播\n",
        "      optimizer.step() # 勾配を元にモデルのパラメーター更新\n",
        "      scheduler.step() # オプティマイザーの学習率を下げる\n",
        "\n",
        "      optimizer.zero_grad() # パラメーター更新後は勾配は使用しないためリセットする\n",
        "\n",
        "    model.eval() # モデルを評価モードにする\n",
        "    dev_outputs, dev_labels = [], []\n",
        "    for batch in tqdm.notebook.tqdm(dev_dataloader, desc=\"Evaluating\"): # 開発用データローダーからバッチを取り出す\n",
        "      with torch.no_grad(): # 学習は行わないため、学習にしか関係しない計算は省くことでコストを下げ速度を上げる。\n",
        "        outputs = model(\n",
        "          input_ids=batch[\"input_ids\"].to(DEVICE),\n",
        "          token_type_ids=batch[\"token_type_ids\"].to(DEVICE),\n",
        "          attention_mask=batch[\"attention_mask\"].to(DEVICE)\n",
        "        ) # モデルの結果予測を行う\n",
        "      outputs = outputs.cpu() # モデル結果がGPUに乗ったままになっているのでCPUに送信する。\n",
        "      dev_outputs.append(outputs)\n",
        "      dev_labels.append(batch[\"labels\"])\n",
        "\n",
        "    dev_outputs = torch.cat(dev_outputs, dim=0) # 出力を連結する\n",
        "    dev_labels = torch.cat(dev_labels, dim=0) # 正答ラベルを連結する\n",
        "\n",
        "    scores = calc_accuracy(dev_outputs, dev_labels) # 正答率で評価を行う。\n",
        "    print(f\"Epoch {epoch+1} : Dev Score\", scores)\n",
        "    if best_score is None or scores >= best_score: # 初めて評価を行った場合、もしくは最良スコアを更新した場合。\n",
        "      best_score = scores # 最良スコアの更新\n",
        "\n",
        "      # 以下はモデル保存用のテンプレート\n",
        "      model_to_save = model.module if hasattr(model, \"module\") else model\n",
        "      torch.save(model_to_save.state_dict(), FILTER_MODEL_PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}